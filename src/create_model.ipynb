{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa27b22d",
   "metadata": {},
   "source": [
    "# Create Logistic Model - Handle Imbalaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae570751",
   "metadata": {},
   "source": [
    "## Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "7a5672e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import ClusterCentroids, RandomUnderSampler, TomekLinks\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0959c3",
   "metadata": {},
   "source": [
    "### Laod the Dataset into Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "95da6d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = \"/Users/lancehester/Documents/ml_handling_imbalanced_data/data/clean_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "9f1d97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "64c82b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>class</th>\n",
       "      <th>sex_I</th>\n",
       "      <th>sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n",
       "0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   shell_weight  class  sex_I  sex_M  \n",
       "0         0.150      0  False   True  \n",
       "1         0.070      0  False   True  \n",
       "2         0.210      0  False  False  \n",
       "3         0.155      0  False   True  \n",
       "4         0.055      0   True  False  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a795b7b",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Start Build the Binary Logistic Classifier\n",
    "\n",
    "* `stratify` says to give equal proportions of class column to both train and test dataframes\n",
    "* 0.2 or 20% of the dataset is used for testing\n",
    "* random state helps us to see same result each time this is run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "70d292fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Training and Test Sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, stratify=df[\"class\"], random_state=999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "c4ea3569",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=df_train.drop(columns=[\"class\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "d960a372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>class</th>\n",
       "      <th>sex_I</th>\n",
       "      <th>sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>0.505</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5605</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.1435</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.450</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>0.415</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.3160</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.0795</td>\n",
       "      <td>0.0925</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>0.575</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.3485</td>\n",
       "      <td>0.1735</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>0.620</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.180</td>\n",
       "      <td>1.3315</td>\n",
       "      <td>0.5940</td>\n",
       "      <td>0.2760</td>\n",
       "      <td>0.3880</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>0.650</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.175</td>\n",
       "      <td>1.2655</td>\n",
       "      <td>0.6150</td>\n",
       "      <td>0.2775</td>\n",
       "      <td>0.3360</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>0.630</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.2330</td>\n",
       "      <td>0.6565</td>\n",
       "      <td>0.2315</td>\n",
       "      <td>0.3035</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0.360</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>0.0840</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>0.635</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.2695</td>\n",
       "      <td>0.5635</td>\n",
       "      <td>0.3065</td>\n",
       "      <td>0.3395</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>0.620</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.185</td>\n",
       "      <td>1.5275</td>\n",
       "      <td>0.6900</td>\n",
       "      <td>0.3680</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>835 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n",
       "2883   0.505     0.400   0.125        0.5605          0.2255          0.1435   \n",
       "800    0.450     0.335   0.125        0.3490          0.1190          0.1055   \n",
       "2005   0.415     0.325   0.110        0.3160          0.1385          0.0795   \n",
       "455    0.575     0.470   0.140        0.8375          0.3485          0.1735   \n",
       "1008   0.620     0.510   0.180        1.3315          0.5940          0.2760   \n",
       "...      ...       ...     ...           ...             ...             ...   \n",
       "2691   0.650     0.520   0.175        1.2655          0.6150          0.2775   \n",
       "1695   0.630     0.485   0.165        1.2330          0.6565          0.2315   \n",
       "436    0.360     0.275   0.095        0.2170          0.0840          0.0435   \n",
       "1941   0.635     0.485   0.165        1.2695          0.5635          0.3065   \n",
       "754    0.620     0.505   0.185        1.5275          0.6900          0.3680   \n",
       "\n",
       "      shell_weight  class  sex_I  sex_M  \n",
       "2883        0.1700      0   True  False  \n",
       "800         0.1150      0  False   True  \n",
       "2005        0.0925      0   True  False  \n",
       "455         0.2400      0  False   True  \n",
       "1008        0.3880      0  False  False  \n",
       "...            ...    ...    ...    ...  \n",
       "2691        0.3360      0  False   True  \n",
       "1695        0.3035      0  False   True  \n",
       "436         0.0900      0   True  False  \n",
       "1941        0.3395      0  False  False  \n",
       "754         0.3500      0  False   True  \n",
       "\n",
       "[835 rows x 10 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "53d8d2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    0.992213\n",
       "1    0.007787\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the stratisfy worked by looking at proportion of classes in training and test dataframes\n",
    "df_train[\"class\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "5c4dd8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    0.992814\n",
       "1    0.007186\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"class\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15785f3",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Handling Imbalanced Datasets\n",
    "\n",
    "* Oversampling (i.e., increase the number of minority class sets to rival proportion of majority class)\n",
    "\n",
    "* Undersampling (i.e., decrease the number of majority class sets to rival proportion of minority class)\n",
    "\n",
    "* Combining Oversampling and Undersampling\n",
    "\n",
    "* Weighing the Classes Differently\n",
    "\n",
    "* Chaning Algorithms \n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f59b76",
   "metadata": {},
   "source": [
    "#### --- Oversampling - Simple Random Oversampling\n",
    "\n",
    "Take copies **with replacement**\n",
    "\n",
    "* use pandas \n",
    "* use imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f7258358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    3313\n",
       "1      26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)\n",
    "df_train[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "ba94610f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3339,)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_num_positive = df_train[\"class\"] == 1 # Class == 1 == Positive\n",
    "current_num_positive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "536eb28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    3313\n",
       "1    3313\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Pandas for simple sample and replace\n",
    "current_num_positive = df_train[\"class\"] == 1 # Class == 1 == Positive\n",
    "num_to_oversample = len(df_train) - 2*current_num_positive.sum()\n",
    "df_positive_oversample = df_train[current_num_positive].sample(n=num_to_oversample, replace=True, random_state=999)\n",
    "\n",
    "#outer join (right join of dataframes) - keep df_train matching indices and add df_positive's why we did 2*current\n",
    "df_train_oversample = pd.concat([df_train, df_positive_oversample]) \n",
    "df_train_oversample[\"class\"].value_counts() # verify that we have the same count majority and minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "40efbf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>class</th>\n",
       "      <th>sex_I</th>\n",
       "      <th>sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3059</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.180</td>\n",
       "      <td>1.310</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.4695</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n",
       "457     0.36     0.280   0.105         0.199          0.0695           0.045   \n",
       "3059    0.63     0.495   0.180         1.310          0.4950           0.295   \n",
       "\n",
       "      shell_weight  class  sex_I  sex_M  \n",
       "457         0.0800      0   True  False  \n",
       "3059        0.4695      0  False   True  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_oversample.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "fa22a444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(3287)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_oversample.duplicated().sum() #see we have duplicated this many rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "6d1addea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Logisitic Regression to the new Balanced data set to see how fixing imbalances improves the logistic regression classifier\n",
    "\n",
    "logistic_classifier = LogisticRegression(random_state=999) # instantiate LogisticRegression class\n",
    "\n",
    "logistic_classifier.fit(df_train_oversample[features], df_train_oversample[\"class\"])\n",
    "y_pred = logistic_classifier.predict_proba(df_test[features])[:,1] #gets prediction of the Positive class, Class =1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "4ac6ed37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.09907933e-01, 2.76187767e-01, 1.03570085e-01, 4.35112261e-01,\n",
       "       5.22016253e-01, 4.88436783e-01, 8.38664353e-01, 1.38384639e-01,\n",
       "       8.16057635e-02, 1.83765975e-01, 8.10406703e-02, 2.26678947e-01,\n",
       "       3.20730486e-01, 9.84910379e-02, 1.94785695e-01, 2.89706667e-01,\n",
       "       2.25986003e-01, 1.17567675e-01, 2.06352161e-01, 2.46865789e-01,\n",
       "       4.98698408e-01, 6.14789115e-01, 7.43350220e-01, 3.73908413e-01,\n",
       "       3.17560087e-01, 9.22186098e-02, 2.12755871e-01, 1.20645524e-01,\n",
       "       4.69316584e-02, 1.57436948e-01, 4.04000605e-01, 1.16337672e-01,\n",
       "       6.55898141e-01, 4.08658526e-01, 5.33538895e-01, 2.41522112e-01,\n",
       "       2.83621559e-01, 1.90606925e-01, 4.93535836e-02, 3.72714442e-01,\n",
       "       2.00178010e-01, 1.97893085e-01, 8.89165262e-01, 3.78327287e-01,\n",
       "       7.03163578e-01, 7.38607998e-02, 1.18361572e-01, 2.62637722e-01,\n",
       "       2.76820769e-01, 3.14652255e-01, 3.23008909e-01, 4.37748965e-01,\n",
       "       1.54938081e-01, 6.29276244e-01, 2.70297285e-01, 6.14007523e-02,\n",
       "       1.41035314e-01, 4.75835660e-01, 4.99274235e-02, 6.14242961e-01,\n",
       "       4.81911879e-01, 6.25432678e-01, 1.31999054e-01, 1.95788129e-01,\n",
       "       3.25072383e-01, 1.38163605e-01, 3.92371894e-01, 9.91362551e-02,\n",
       "       1.37365160e-01, 3.29933317e-01, 3.38648937e-02, 3.88489055e-01,\n",
       "       5.64908333e-02, 5.13319542e-01, 2.01126835e-01, 2.14227002e-01,\n",
       "       4.86106479e-01, 2.26152102e-01, 2.78590233e-01, 9.45402458e-02,\n",
       "       2.11948636e-01, 2.78471291e-01, 7.44913008e-02, 2.63780533e-01,\n",
       "       3.15158770e-01, 1.59080824e-01, 8.52470793e-02, 1.75532938e-01,\n",
       "       5.19734972e-01, 5.31853937e-01, 7.93898195e-01, 2.58612411e-01,\n",
       "       1.06437971e-01, 4.40151101e-01, 8.70302023e-01, 3.70452842e-01,\n",
       "       3.63315360e-01, 3.49742053e-01, 2.91897444e-02, 4.48433998e-01,\n",
       "       5.89042340e-02, 1.26181259e-01, 1.68299047e-01, 3.50543018e-01,\n",
       "       5.85151031e-01, 3.40312837e-01, 5.07421456e-01, 8.50182230e-02,\n",
       "       6.39781479e-02, 6.86562882e-01, 3.22935635e-01, 5.03623136e-02,\n",
       "       2.87807189e-01, 7.88573175e-01, 8.24159578e-01, 6.73814172e-01,\n",
       "       7.48344729e-01, 6.99303117e-01, 2.88242130e-01, 4.35872543e-02,\n",
       "       3.08643220e-01, 6.91079045e-01, 1.03288188e-01, 6.14586199e-01,\n",
       "       3.64121228e-01, 1.81626538e-01, 9.11291392e-02, 8.83155737e-02,\n",
       "       8.11553645e-01, 8.11943132e-02, 5.84219009e-01, 5.45470312e-01,\n",
       "       7.52193348e-02, 1.80734233e-01, 1.05708682e-01, 1.87388571e-04,\n",
       "       1.45159003e-01, 6.91593169e-01, 6.13987745e-01, 2.66867711e-01,\n",
       "       2.47359814e-01, 2.28977990e-01, 3.92036312e-01, 6.17242753e-02,\n",
       "       3.23239314e-01, 7.16832021e-01, 1.91307981e-01, 8.87374336e-01,\n",
       "       4.43631299e-01, 5.19895433e-01, 4.14708890e-02, 4.52061420e-01,\n",
       "       1.52884804e-01, 4.41206700e-01, 1.49870929e-01, 9.55393583e-02,\n",
       "       1.61000526e-01, 2.77029355e-01, 3.42274243e-01, 1.46046901e-01,\n",
       "       6.55598736e-02, 2.42379531e-01, 5.75101003e-01, 2.80907672e-01,\n",
       "       7.35860543e-02, 2.82987221e-02, 4.22447368e-02, 3.12090118e-01,\n",
       "       4.93409489e-01, 5.53588676e-01, 7.39301093e-01, 3.84919609e-01,\n",
       "       1.60553009e-01, 9.16731885e-02, 1.17499320e-01, 3.10443238e-01,\n",
       "       7.42260060e-01, 1.86756020e-01, 4.50745147e-01, 1.68965088e-01,\n",
       "       1.20517316e-01, 2.09444628e-02, 6.27514987e-01, 1.69975858e-01,\n",
       "       1.34843919e-01, 8.96422084e-01, 2.24024673e-01, 2.98381029e-01,\n",
       "       8.92185419e-02, 4.12979945e-01, 2.19806882e-01, 4.54208833e-01,\n",
       "       8.77426262e-01, 4.57995082e-01, 9.51998988e-02, 3.10463362e-01,\n",
       "       8.14755813e-02, 6.34121640e-01, 3.85248129e-01, 8.23405794e-02,\n",
       "       4.09568527e-01, 2.23363758e-01, 7.70930659e-01, 1.05800658e-01,\n",
       "       2.01829557e-01, 3.89549443e-01, 1.80131720e-01, 7.16776359e-01,\n",
       "       1.61998562e-01, 9.86869313e-01, 5.28024314e-01, 3.14713282e-01,\n",
       "       1.90577453e-01, 5.82704337e-01, 2.99979388e-01, 3.34287815e-01,\n",
       "       2.28092249e-01, 2.15327783e-01, 1.02648475e-01, 8.43546477e-01,\n",
       "       8.21474015e-01, 2.37269628e-01, 2.44391269e-02, 6.71911797e-01,\n",
       "       4.24300346e-01, 4.14632993e-01, 4.19889403e-01, 2.00986783e-01,\n",
       "       9.80375146e-01, 2.13800960e-01, 5.20668804e-01, 5.18617513e-01,\n",
       "       2.29504299e-01, 1.55530528e-01, 8.99381685e-02, 9.95299356e-02,\n",
       "       2.22883842e-01, 4.02470452e-01, 5.44012182e-02, 4.75042518e-02,\n",
       "       2.51273821e-01, 6.11150557e-01, 4.49700127e-01, 1.57789756e-01,\n",
       "       5.11852462e-01, 6.36423138e-01, 3.87561413e-01, 3.37240677e-01,\n",
       "       1.72849373e-01, 2.80261271e-01, 2.55682591e-01, 2.21070539e-01,\n",
       "       1.76837628e-01, 2.64271075e-01, 5.43812751e-01, 1.46557644e-01,\n",
       "       6.52867657e-02, 3.39120482e-01, 1.01080151e-01, 1.05062364e-01,\n",
       "       6.92358156e-01, 1.09422133e-01, 5.58817905e-02, 4.54920175e-01,\n",
       "       3.87535608e-01, 6.47211500e-01, 5.76253498e-02, 7.72573462e-01,\n",
       "       2.60391883e-01, 4.84646774e-01, 3.47359317e-01, 3.30890990e-01,\n",
       "       2.83284950e-01, 8.42200987e-01, 6.77092382e-01, 6.84878574e-01,\n",
       "       4.45419613e-01, 2.73448434e-01, 9.25212435e-02, 2.44416032e-01,\n",
       "       2.50821885e-01, 1.67372175e-02, 5.08199455e-01, 7.37668119e-01,\n",
       "       9.72387480e-02, 6.13419410e-02, 3.28064123e-02, 5.62661635e-01,\n",
       "       9.09185567e-02, 1.88673965e-01, 2.27625234e-02, 2.46982295e-01,\n",
       "       1.81808878e-01, 1.30061367e-01, 1.22305193e-01, 5.54350420e-01,\n",
       "       6.68199551e-01, 6.92260780e-02, 2.07767122e-01, 5.64418822e-01,\n",
       "       1.60613205e-01, 7.90491483e-01, 2.87023050e-01, 1.67883912e-01,\n",
       "       7.41773616e-02, 2.45546115e-01, 5.05215221e-01, 5.69594009e-02,\n",
       "       9.23417099e-01, 4.94035525e-01, 6.28427417e-01, 1.01734996e-01,\n",
       "       2.25675596e-01, 9.78886122e-02, 3.08630505e-01, 2.81784565e-02,\n",
       "       1.58442826e-01, 7.34535411e-01, 4.91505951e-01, 3.66251900e-01,\n",
       "       9.18536123e-01, 6.00675965e-01, 7.74458388e-02, 1.76584776e-01,\n",
       "       4.16431265e-02, 7.47580070e-01, 8.26251664e-01, 2.14149642e-01,\n",
       "       3.82542091e-01, 4.87731414e-02, 6.41801641e-01, 3.95791262e-01,\n",
       "       4.12678855e-01, 1.95285822e-01, 1.76905170e-01, 3.67663271e-01,\n",
       "       8.09814492e-01, 7.15280062e-01, 8.40660333e-01, 3.74986534e-02,\n",
       "       6.54474358e-01, 4.61078684e-01, 4.47735929e-01, 6.00536871e-01,\n",
       "       4.10548740e-01, 1.56256666e-01, 1.67629085e-01, 1.92744826e-01,\n",
       "       7.09969874e-01, 2.16248239e-01, 2.69285992e-01, 4.04204591e-01,\n",
       "       9.18541861e-02, 2.30676524e-01, 4.76629040e-02, 8.92318661e-01,\n",
       "       1.12453422e-01, 2.79587574e-01, 1.71544000e-01, 9.06490544e-01,\n",
       "       4.85476430e-01, 3.06933979e-01, 6.84497146e-01, 2.68365342e-01,\n",
       "       2.99259314e-01, 1.86156327e-01, 4.71730995e-01, 2.26805366e-01,\n",
       "       3.31371802e-01, 2.58506714e-01, 8.99620407e-02, 2.88582942e-01,\n",
       "       3.01194270e-02, 5.84080596e-01, 1.51410895e-01, 3.66275007e-01,\n",
       "       4.65223300e-01, 7.72060146e-02, 5.73935465e-01, 6.09483324e-01,\n",
       "       3.95747747e-01, 2.77550095e-01, 2.62116236e-01, 3.87365930e-01,\n",
       "       1.12080584e-01, 2.50745521e-01, 3.59687418e-01, 1.39383212e-01,\n",
       "       1.90722073e-01, 8.10365518e-02, 2.38980385e-01, 4.23744644e-01,\n",
       "       1.41118123e-01, 2.60944883e-01, 7.20435303e-02, 3.50146365e-01,\n",
       "       9.18136417e-02, 5.28761447e-02, 4.24068825e-01, 8.21780552e-02,\n",
       "       2.97568332e-02, 2.90824588e-01, 3.63425920e-01, 5.22157935e-01,\n",
       "       4.23149773e-01, 7.96302078e-02, 3.49635805e-01, 5.35975792e-01,\n",
       "       5.89786609e-02, 7.78741998e-01, 7.34229570e-01, 1.88870624e-01,\n",
       "       7.98291105e-01, 2.54555023e-01, 6.18129817e-02, 6.33566321e-01,\n",
       "       1.14860026e-01, 7.51886881e-01, 7.53123430e-01, 4.64162639e-01,\n",
       "       1.66542913e-01, 1.05388343e-01, 3.64073658e-01, 2.04397271e-01,\n",
       "       1.50707834e-01, 2.23946688e-01, 4.59248086e-01, 3.62436235e-01,\n",
       "       2.25320071e-01, 1.57698254e-01, 4.95078182e-01, 3.96910363e-01,\n",
       "       1.49067598e-01, 3.06045958e-01, 2.83109001e-01, 2.27802026e-01,\n",
       "       2.46268038e-01, 8.25859714e-01, 1.01200249e-01, 2.45394391e-01,\n",
       "       3.41456099e-01, 7.60581055e-02, 2.90451462e-01, 3.20724673e-01,\n",
       "       1.63140475e-01, 3.14776455e-01, 1.97103066e-01, 2.53290954e-01,\n",
       "       5.44299983e-01, 8.38389678e-02, 1.89486855e-01, 4.24793110e-01,\n",
       "       1.97919982e-01, 5.13281033e-01, 2.46837821e-01, 3.35077266e-01,\n",
       "       3.10395227e-01, 4.77833206e-01, 2.50943422e-01, 6.47006884e-02,\n",
       "       3.17866935e-01, 3.12331152e-01, 1.45556938e-01, 9.74526367e-01,\n",
       "       5.16760641e-01, 1.59650180e-01, 1.58704274e-01, 3.95969694e-01,\n",
       "       1.01872733e-01, 6.71716285e-02, 3.11300039e-01, 3.17612661e-01,\n",
       "       6.45582059e-01, 2.12241265e-01, 5.24962535e-01, 4.06147776e-01,\n",
       "       5.97346337e-01, 1.63260249e-01, 3.19937565e-02, 1.75091365e-01,\n",
       "       7.26367017e-02, 4.88088539e-01, 2.58102902e-01, 3.92890807e-01,\n",
       "       6.22197624e-01, 2.71769486e-01, 4.64432076e-01, 3.78447044e-01,\n",
       "       2.35461551e-01, 7.31151981e-01, 4.87692067e-02, 6.89199294e-02,\n",
       "       8.53408577e-01, 7.36751445e-01, 6.08121898e-02, 7.82390399e-02,\n",
       "       1.97461566e-01, 1.18887168e-01, 2.98659102e-01, 1.32776160e-01,\n",
       "       4.47943518e-01, 2.32599889e-01, 2.45051606e-01, 4.72310080e-01,\n",
       "       6.16112556e-02, 2.99040048e-01, 1.27603479e-01, 4.57413222e-01,\n",
       "       6.34838014e-01, 2.48867298e-01, 3.74172699e-01, 2.23797796e-01,\n",
       "       3.92795366e-02, 2.19638145e-01, 2.95707093e-02, 3.42924758e-01,\n",
       "       8.60789529e-01, 3.45315087e-01, 3.83122114e-02, 2.45846453e-01,\n",
       "       7.09185320e-02, 2.27314382e-01, 2.11020672e-01, 3.68975266e-01,\n",
       "       3.85601352e-01, 1.71098861e-01, 9.35458558e-02, 1.16851201e-01,\n",
       "       5.83428189e-02, 3.15495968e-01, 2.90454717e-01, 1.09250030e-01,\n",
       "       7.37507994e-01, 9.42836472e-02, 9.80289966e-01, 6.86385708e-02,\n",
       "       5.44742876e-01, 2.05620804e-01, 1.27633856e-01, 2.42911702e-01,\n",
       "       6.24873181e-01, 1.41311986e-01, 1.98307230e-01, 2.91788697e-01,\n",
       "       5.99330501e-02, 5.30114366e-01, 2.99050179e-01, 2.77824487e-01,\n",
       "       4.85957153e-01, 3.77326563e-01, 4.91409195e-01, 1.07601872e-01,\n",
       "       9.22697099e-01, 1.32569844e-01, 1.43190106e-01, 5.47211541e-01,\n",
       "       7.18681501e-01, 7.98955072e-01, 6.66827456e-01, 1.74159769e-01,\n",
       "       1.37228480e-01, 3.19370487e-01, 1.05875564e-01, 4.58190193e-01,\n",
       "       1.78880409e-01, 4.94401179e-01, 3.50810632e-01, 4.44645344e-01,\n",
       "       9.89965869e-02, 8.69279699e-02, 4.51825663e-01, 5.17317398e-01,\n",
       "       4.86828242e-01, 4.09743398e-01, 3.04262332e-01, 5.33829060e-01,\n",
       "       2.61706240e-01, 4.25652863e-01, 5.99277695e-01, 1.19530885e-01,\n",
       "       1.57576594e-01, 7.50835787e-02, 1.62584322e-01, 8.92463219e-02,\n",
       "       9.71203877e-02, 6.15679150e-01, 6.72499562e-02, 7.21772240e-01,\n",
       "       1.86510526e-01, 4.21229417e-02, 9.74092788e-01, 9.76602088e-01,\n",
       "       2.73565351e-02, 8.62202302e-02, 4.78154334e-01, 9.39161063e-02,\n",
       "       2.78379717e-02, 3.06628849e-01, 2.39200561e-01, 3.37042581e-02,\n",
       "       4.71306589e-02, 2.31934057e-01, 7.84031468e-01, 7.06277229e-02,\n",
       "       1.92587680e-01, 4.33719301e-02, 6.09063509e-02, 1.36612622e-01,\n",
       "       8.23755273e-02, 9.03344358e-01, 1.19636278e-01, 7.24784751e-02,\n",
       "       1.76405873e-01, 1.16991306e-01, 2.97357659e-01, 2.44488372e-01,\n",
       "       1.94099939e-01, 4.51379557e-02, 3.43786284e-01, 7.05885662e-02,\n",
       "       1.40162932e-01, 4.95831494e-01, 2.97260651e-01, 2.54386386e-01,\n",
       "       1.03327592e-01, 5.53838889e-01, 2.89280115e-01, 1.09773438e-01,\n",
       "       1.25830550e-01, 2.97653561e-01, 9.30377063e-01, 8.14859561e-01,\n",
       "       5.97206606e-01, 5.48690071e-02, 3.26815650e-01, 1.52712719e-01,\n",
       "       1.74691794e-01, 3.95213893e-01, 5.64325665e-02, 6.58707196e-01,\n",
       "       7.16488376e-02, 3.22891521e-01, 6.93608159e-01, 9.83068240e-01,\n",
       "       6.20553645e-01, 5.43851151e-01, 2.58024715e-01, 8.43487360e-01,\n",
       "       2.90127117e-01, 3.40007705e-01, 6.46088674e-02, 1.92538275e-01,\n",
       "       7.90606178e-01, 3.38702628e-02, 1.09259052e-01, 8.23873774e-02,\n",
       "       5.29331881e-01, 7.39495621e-02, 6.01285027e-01, 6.19241068e-01,\n",
       "       2.31913552e-01, 1.26651602e-01, 1.09663496e-01, 7.56647078e-01,\n",
       "       4.87236210e-01, 8.87814501e-02, 7.15032418e-01, 3.50509732e-01,\n",
       "       2.11491711e-01, 4.14439168e-01, 1.88105087e-01, 3.32091358e-01,\n",
       "       1.12222588e-01, 5.62422599e-02, 1.65248228e-01, 6.36841811e-01,\n",
       "       1.22034869e-01, 2.53976881e-01, 2.06033023e-01, 7.49816771e-01,\n",
       "       4.80547818e-01, 5.82400460e-01, 8.76753189e-02, 6.31115361e-02,\n",
       "       5.70651702e-01, 6.20858471e-02, 6.57241751e-01, 2.43308242e-01,\n",
       "       5.76643672e-01, 2.74123209e-01, 8.20938467e-02, 3.09158730e-01,\n",
       "       3.51756736e-01, 4.91885528e-01, 4.96689240e-01, 2.56523189e-01,\n",
       "       2.56097435e-01, 3.48790923e-01, 1.75611287e-01, 4.94962117e-01,\n",
       "       1.60174103e-01, 1.16207145e-01, 1.83365856e-01, 7.30132915e-02,\n",
       "       3.80723585e-01, 6.39609386e-01, 8.75556310e-01, 3.61751276e-01,\n",
       "       1.74078182e-01, 5.26039872e-02, 1.16245315e-01, 5.44649903e-01,\n",
       "       3.53199439e-01, 2.42749080e-01, 2.16800751e-01, 5.22702911e-01,\n",
       "       1.20297919e-01, 6.76023289e-02, 5.88366394e-02, 8.95833873e-01,\n",
       "       1.44122075e-01, 2.69090178e-01, 2.98403821e-01, 1.98881717e-01,\n",
       "       3.71768227e-01, 2.91641808e-01, 5.81202615e-01, 6.11538113e-02,\n",
       "       8.90446708e-02, 2.61178463e-01, 7.26569880e-01, 8.51287563e-01,\n",
       "       9.43560416e-01, 7.59322907e-01, 4.47117684e-02, 5.80351904e-01,\n",
       "       6.31110473e-02, 6.96549378e-01, 5.84262757e-01, 3.30009948e-01,\n",
       "       1.34464487e-01, 4.08275182e-01, 5.33751940e-01, 2.50803000e-01,\n",
       "       1.22283128e-01, 5.27005813e-01, 1.07456591e-01, 9.66655774e-02,\n",
       "       3.40142166e-01, 5.49184641e-01, 4.43737541e-01, 3.95873432e-01,\n",
       "       2.99284279e-01, 1.94790912e-01, 4.96767063e-01, 1.94561372e-01,\n",
       "       4.23626098e-01, 1.15599137e-01, 8.83668653e-02, 2.03220783e-01,\n",
       "       1.06268005e-01, 3.48110733e-01, 3.24746296e-01, 6.26869961e-01,\n",
       "       7.52965803e-01, 5.88087093e-01, 2.43429472e-01, 9.88499853e-02,\n",
       "       1.96688479e-01, 2.39350590e-01, 8.63122986e-01, 2.92342142e-01,\n",
       "       5.15465907e-01, 2.54766005e-01, 2.35494237e-01, 1.90395645e-01,\n",
       "       5.82162705e-02, 5.84477616e-01, 8.15367022e-02, 7.36728491e-01,\n",
       "       2.00240588e-01, 8.29387436e-02, 1.66550678e-01, 5.09403479e-01,\n",
       "       1.47729325e-01, 7.22992113e-01, 6.42471415e-01, 1.36218417e-01,\n",
       "       2.52628658e-01, 4.98110969e-02, 1.15056544e-01, 3.29118085e-01,\n",
       "       9.46735550e-02, 6.11185630e-02, 1.69693702e-01, 3.47763251e-01,\n",
       "       7.57026036e-02, 2.72451501e-01, 2.89012889e-01, 9.49073513e-01,\n",
       "       7.98643131e-02, 5.75914395e-01, 5.27167068e-02, 1.24961928e-01,\n",
       "       7.65139605e-02, 6.92975450e-01, 4.79798906e-01, 8.26520055e-01,\n",
       "       1.38834838e-01, 1.41969938e-01, 3.96746010e-01, 2.23249436e-02,\n",
       "       3.64257904e-01, 1.04279546e-01, 6.19405075e-01, 4.38788073e-01,\n",
       "       2.58588810e-01, 4.45232053e-01, 1.94145339e-01, 8.52544247e-01,\n",
       "       6.00052802e-01, 4.87451574e-01, 1.75525995e-01, 3.83127544e-01,\n",
       "       2.91191482e-01, 2.43896183e-01, 2.77798173e-01, 6.46727427e-01,\n",
       "       1.60402231e-01, 6.88689208e-01, 3.22642661e-01, 1.53816242e-01,\n",
       "       1.03476582e-01, 4.04972900e-01, 3.50208824e-01])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "600de504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9225975070365903)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at roc_auc_score\n",
    "roc_auc_score(df_test[\"class\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ab7a0d",
   "metadata": {},
   "source": [
    "#### Performing Simple Random Oversampling with `imbalanced-learn`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "0e80155b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    3313\n",
       "1    3313\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_over_sampler = RandomOverSampler(random_state=999)\n",
    "X_resampled, y_resampled = random_over_sampler.fit_resample(df_train[features], df_train[\"class\"])\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "d702acfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_classifier = LogisticRegression(random_state=999) # instantiate LogisticRegression class\n",
    "\n",
    "logistic_classifier.fit(df_train_oversample[features], df_train_oversample[\"class\"])\n",
    "y_pred = logistic_classifier.predict_proba(df_test[features])[:,1] #gets prediction of the Positive class, Class =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "e24cc379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9225975070365903)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at roc_auc_score\n",
    "roc_auc_score(df_test[\"class\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f91c22",
   "metadata": {},
   "source": [
    "### Oversampling with Shrinkage\n",
    "\n",
    "Here we add some noise to the random sampling so that we do not get exact duplicates of sampled values. It is like adding a little bit of jitter so that the values are close, but not exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "db6c0b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_over_sampler = RandomOverSampler(random_state=999, shrinkage=0.1) #Adding extra noise value 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "4e8c08ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = random_over_sampler.fit_resample(df_train[features], df_train[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "df9c2489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    3313\n",
       "1    3313\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "a7f89c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for duplicates. We expect less duplicates because of the shrinkage = 0.1 use\n",
    "X_resampled.duplicated().sum() #see we have duplicated this many rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "67d752e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.42621632488942496)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_classifier = LogisticRegression(random_state=999) # instantiate LogisticRegression class\n",
    "\n",
    "logistic_classifier.fit(X_resampled, y_resampled)\n",
    "y_pred = logistic_classifier.predict_proba(df_test[features])[:,1] #gets prediction of the Positive class, Class =1\n",
    "\n",
    "# Look at roc_auc_score\n",
    "roc_auc_score(df_test[\"class\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc34254",
   "metadata": {},
   "source": [
    "### Oversampling using Synthetic Minority Over-sampling TEchnique `(SMOTE)`\n",
    "\n",
    "Uses nearest neighbors to make synthetic random samples to increase the minority set.\n",
    "\n",
    "Let's you add more information to the the training model which helps the model learn better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "a4b3cc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    3313\n",
       "1    3313\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote = SMOTE(random_state=999)\n",
    "X_resampled, y_resampled = smote.fit_resample(df_train[features], df_train[\"class\"])\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "8e18644c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9236027342179333)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_classifier = LogisticRegression(random_state=888)\n",
    "\n",
    "logistic_classifier.fit(X_resampled, y_resampled)\n",
    "y_pred = logistic_classifier.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "roc_auc_score(df_test[\"class\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19733315",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Undersampling \n",
    "\n",
    "Removes examples of the majority class to balance the data set (i.e., reduce examples). In other words, we randomly sample observations of the majority class equal to size of the minority class. The problem with this approach is that it may mean that we remove useful information from the dataset.\n",
    "\n",
    "\n",
    "* **Simple random undersampling:** the basic approach of random sampling from the majority class.\n",
    "\n",
    "* **Undersampling using K-Means:** synthesize based on the cluster centroids.\n",
    "\n",
    "* **Undersampling using Tomek links:** detects and removes samples from Tomek links.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e86516",
   "metadata": {},
   "source": [
    "#### -- Simple Random Undersampling \n",
    "\n",
    "We take a sample from the majority class, to have the same size as the minority class. So there are risks of removing useful information from the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "5b5b3db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    26\n",
       "1    26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Random Undersampling Using Pandas\n",
    "msk_negative = df_train[\"class\"] == 0\n",
    "msk_positive = df_train[\"class\"] == 1\n",
    "\n",
    "df_negative_undersample = df_train[msk_negative].sample(n=msk_positive.sum(), random_state=999) #sampling WITHOUT replacement\n",
    "df_train_undersample = pd.concat([df_negative_undersample, df_train[msk_positive]]) #Outer join right \n",
    "\n",
    "df_train_undersample[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "de21e872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.72778447929232)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_classifier = LogisticRegression(random_state=999)\n",
    "\n",
    "logistic_classifier.fit(df_train_undersample[features], df_train_undersample[\"class\"])\n",
    "y_pred = logistic_classifier.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "roc_auc_score(df_test[\"class\"], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "0804e388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    26\n",
       "1    26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Random Undersampling Using imbalanced-learn\n",
    "random_under_sampler = RandomUnderSampler(random_state=999)\n",
    "X_resampled, y_resampled = random_under_sampler.fit_resample(df_train[features], df_train[\"class\"])\n",
    "\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "37081e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.72778447929232)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_classifier = LogisticRegression(random_state=999)\n",
    "\n",
    "logistic_classifier.fit(X_resampled, y_resampled)\n",
    "y_pred = logistic_classifier.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "roc_auc_score(df_test[\"class\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d9329",
   "metadata": {},
   "source": [
    "Simple Random Undersampling Results\n",
    "\n",
    "AUC scores for Simple Random Undersampling (e.g., 0.72778447929232) are much lower than the Oversampling examples. A reason for this decrease in AUC value is because the minority class has a small number of samples. In Undersampling we removed a lot of information when undersampling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37daeac2",
   "metadata": {},
   "source": [
    "#### -- Undersampling using `K-Means/Cluster Centroids`\n",
    "\n",
    "Besides random sampling, we could also use the cluster centroid of the K-Means method as the new sample of the majority class. This means the new sample of the majority class is not the original data anymore. They are synthesized with cluster centroids. So the new sample should be more representative of the actual majority class data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "cde16039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    26\n",
       "1    26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = ClusterCentroids(random_state=999)\n",
    "X_resampled, y_resampled = cc.fit_resample(df_train[features], df_train[\"class\"])\n",
    "\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f67fd59",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "4c13ff41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8021712907117008)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_classifier = LogisticRegression(random_state=999)\n",
    "\n",
    "logistic_classifier.fit(X_resampled, y_resampled)\n",
    "y_pred = logistic_classifier.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "roc_auc_score(df_test[\"class\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281bf317",
   "metadata": {},
   "source": [
    "The AUC of K-Means/Cluster Centroid Undersampling performs slightly better than just Simple Random Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fd2ea6",
   "metadata": {},
   "source": [
    "#### -- Undersampling using `Tomek Links`\n",
    "\n",
    "This method detects Tomek links and removes samples based on them.\n",
    "\n",
    "A [Tomek link](https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis) removes unwanted overlap between classes where majority class links are removed until all minimally distanced nearest neighbor pairs are of the same class.\n",
    "\n",
    "\n",
    "It is between two samples of different classes. When the two samples are the nearest neighbors of each other, they form a Tomek link. \n",
    "\n",
    "In our example of the binary classification problem, a Tomek link is a pair of examples from each class that is the closest neighbor across the dataset. After detecting such a link, we could remove data within the pair. Usually, we remove the sample from the majority class to achieve undersampling, i.e., remove the majority class close to the minority class. This removes ambiguity between the two classes.\n",
    "\n",
    "So, undersampling with Tomek links clean up the overlaps between classes, making them easier to distinguish.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "118bac40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    3301\n",
       "1      26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl = TomekLinks()\n",
    "X_resampled, y_resampled = tl.fit_resample(df_train[features], df_train[\"class\"])\n",
    "\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9aceb6",
   "metadata": {},
   "source": [
    "Notice Tomek Links Still results in an imbalanced data set, but the clustering of the two classes is made more distinc for training purposes. Namely, removing overalapping majority classes may help to highlight the key features of the minority class for training purposes. \n",
    "\n",
    "In practice, we would combine the Tomek Link approach with other techniques to get better results. Like Do Undersampling with Tomek then do an Oversample approach ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "8b28ee40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7740249296340973)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_classifier = LogisticRegression(random_state=999)\n",
    "\n",
    "logistic_classifier.fit(X_resampled, y_resampled)\n",
    "y_pred = logistic_classifier.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "roc_auc_score(df_test[\"class\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c9dafc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Combining Oversampling and Undersampling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad99d714",
   "metadata": {},
   "source": [
    "####- SMOTE and Tomek Links\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "db41cfa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    3310\n",
       "1    3310\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_tomek = SMOTETomek(random_state=999)\n",
    "X_resampled, y_resampled = smote_tomek.fit_resample(df_train[features], df_train[\"class\"])\n",
    "\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "702ad8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9236027342179333)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_classifier = LogisticRegression(random_state=999)\n",
    "\n",
    "logistic_classifier.fit(X_resampled, y_resampled)\n",
    "y_pred = logistic_classifier.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "roc_auc_score(df_test[\"class\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a725ed19",
   "metadata": {},
   "source": [
    "#### -- Weighing Classes Differently\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "25b409a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.50392394, 64.21153846])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = compute_class_weight(\"balanced\", classes=df_train[\"class\"].unique(), y=df_train[\"class\"])\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "87cc618d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1669.5\n",
      "1669.5000000000002\n"
     ]
    }
   ],
   "source": [
    "print((df_train[\"class\"] == 0).sum()*weights[0])\n",
    "\n",
    "print((df_train[\"class\"] == 1).sum()*weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "0bdf1cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3339.0\n",
      "3339\n"
     ]
    }
   ],
   "source": [
    "print((df_train[\"class\"] == 0).sum()*weights[0] + (df_train[\"class\"] == 1).sum()*weights[1])\n",
    "\n",
    "print((df_train[\"class\"] == 0).sum() + (df_train[\"class\"] == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "d7abf376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9211901889827101)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_classifier_weighted = LogisticRegression(class_weight='balanced', random_state=999) #use class_weight=\"balanced\"\n",
    "logistic_classifier_weighted.fit(df_train[features], df_train[\"class\"])\n",
    "\n",
    "y_pred = logistic_classifier_weighted.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "roc_auc_score(df_test[\"class\"], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "eb069b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9236027342179333)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_classifier_weighted = LogisticRegression(class_weight={0: 1, 1: 100}, random_state=999)\n",
    "\n",
    "logistic_classifier_weighted.fit(df_train[features], df_train[\"class\"])\n",
    "y_pred = logistic_classifier_weighted.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "roc_auc_score(df_test[\"class\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06166cd",
   "metadata": {},
   "source": [
    "----\n",
    "----\n",
    "\n",
    "# Comparing The Original Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "4857a918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7734217933252916)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_classifier = LogisticRegression(random_state=999)\n",
    "\n",
    "features = df_train.drop(columns=[\"class\"]).columns\n",
    "logistic_classifier.fit(df_train[features], df_train[\"class\"])\n",
    "\n",
    "y_pred = logistic_classifier.predict_proba(df_test[features])[:, 1]\n",
    "\n",
    "roc_auc_score(df_test[\"class\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd722646",
   "metadata": {},
   "source": [
    "---------\n",
    "# Comparing AUC Results for each technique\n",
    "\n",
    "Creating a model with the original dataset without any kind of rebalancing or weighting method yielded a logisitic regression model with a AUC score of 0.7734217933252916\n",
    "\n",
    "The following table shows the AUC results when employing each technique in comparison to using the data set as is:\n",
    "\n",
    "| Technique    | AUC score |\n",
    "| -------- | ------- |\n",
    "| Oversampling with Shrinkage  | 0.4262 |\n",
    "| Simple Random Undersampling  | 0.7278 |\n",
    "| Simple Random Undersampling with Imbalanced Learn  | 0.7278 |\n",
    "| _Original Data Set_  | _0.7734_ |\n",
    "| Tomek Links Undersampling  | 0.7740 |\n",
    "| K-means/Cluster Centroid Undersampling | 0.8476 |\n",
    "| Weighing Classes Differently | 0.9212 |\n",
    "| Simple Random Oversampling  | 0.9226 |\n",
    "| Simple Random Oversampling with Imbalanced Learn  | 0.9226 |\n",
    "| Weighing Classes Differently using specific weights | 0.9236 |\n",
    "| Oversampling with SMOTE  | 0.9236 |\n",
    "| Combine Oversampling and Undersampling (SMOTETomek)  | 0.9236 |\n",
    "\n",
    "\n",
    "Using the various techniques the best AUC results for the last three techniques are approximately the same ` 0.9236`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-handling-imbalanced-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
